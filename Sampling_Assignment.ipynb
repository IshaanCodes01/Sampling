{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sampling Techniques for Imbalanced Credit Card Dataset\n",
        "\n",
        "## Objective\n",
        "To understand the importance of sampling techniques in handling imbalanced datasets and analyze how different sampling strategies affect the performance of various machine learning models.\n",
        "\n",
        "## Problem Statement\n",
        "We are given a highly imbalanced credit card dataset. Our task is to:\n",
        "1. Balance the dataset using different sampling techniques\n",
        "2. Apply five different ML models\n",
        "3. Evaluate and compare the accuracy of each combination\n",
        "\n",
        "## Sampling Techniques:\n",
        "- **Sampling1**: Random Under-Sampling\n",
        "- **Sampling2**: Random Over-Sampling\n",
        "- **Sampling3**: SMOTE (Synthetic Minority Over-sampling Technique)\n",
        "- **Sampling4**: ADASYN (Adaptive Synthetic Sampling)\n",
        "- **Sampling5**: Tomek Links\n",
        "\n",
        "## ML Models:\n",
        "- **M1**: Logistic Regression\n",
        "- **M2**: Decision Tree\n",
        "- **M3**: Random Forest\n",
        "- **M4**: Support Vector Machine (SVM)\n",
        "- **M5**: K-Nearest Neighbors (KNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install and Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 26.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "%pip install pandas numpy scikit-learn imbalanced-learn matplotlib seaborn -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Sampling techniques\n",
        "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
        "\n",
        "# ML Models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.base import clone\n",
        "\n",
        "print(\"✓ All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load and Explore the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Shape: (772, 31)\n",
            "\n",
            "Column Names:\n",
            "['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
            "\n",
            "First 5 rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      1  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('Creditcard_data.csv')\n",
        "\n",
        "# Display basic information\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nColumn Names:\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing Values: 0\n",
            "\n",
            "Dataset Statistics:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "      <td>772.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>283.005181</td>\n",
              "      <td>-0.176963</td>\n",
              "      <td>0.217169</td>\n",
              "      <td>0.875172</td>\n",
              "      <td>0.285628</td>\n",
              "      <td>-0.005029</td>\n",
              "      <td>0.159081</td>\n",
              "      <td>0.123329</td>\n",
              "      <td>-0.057547</td>\n",
              "      <td>-0.030384</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004888</td>\n",
              "      <td>-0.096995</td>\n",
              "      <td>-0.040344</td>\n",
              "      <td>-0.002501</td>\n",
              "      <td>0.114337</td>\n",
              "      <td>0.022782</td>\n",
              "      <td>0.023353</td>\n",
              "      <td>-0.017045</td>\n",
              "      <td>68.668290</td>\n",
              "      <td>0.011658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>171.834196</td>\n",
              "      <td>1.294724</td>\n",
              "      <td>1.173401</td>\n",
              "      <td>1.031878</td>\n",
              "      <td>1.258758</td>\n",
              "      <td>1.098143</td>\n",
              "      <td>1.225682</td>\n",
              "      <td>0.852075</td>\n",
              "      <td>0.830144</td>\n",
              "      <td>0.878183</td>\n",
              "      <td>...</td>\n",
              "      <td>0.609335</td>\n",
              "      <td>0.607228</td>\n",
              "      <td>0.358724</td>\n",
              "      <td>0.621507</td>\n",
              "      <td>0.429667</td>\n",
              "      <td>0.484227</td>\n",
              "      <td>0.300934</td>\n",
              "      <td>0.278332</td>\n",
              "      <td>197.838269</td>\n",
              "      <td>0.107411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-6.093248</td>\n",
              "      <td>-12.114213</td>\n",
              "      <td>-5.694973</td>\n",
              "      <td>-4.657545</td>\n",
              "      <td>-6.631951</td>\n",
              "      <td>-3.498447</td>\n",
              "      <td>-4.925568</td>\n",
              "      <td>-7.494658</td>\n",
              "      <td>-2.770089</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.134608</td>\n",
              "      <td>-2.776923</td>\n",
              "      <td>-3.553381</td>\n",
              "      <td>-1.867208</td>\n",
              "      <td>-1.389079</td>\n",
              "      <td>-1.243924</td>\n",
              "      <td>-2.377933</td>\n",
              "      <td>-2.735623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>126.500000</td>\n",
              "      <td>-0.896416</td>\n",
              "      <td>-0.174684</td>\n",
              "      <td>0.308677</td>\n",
              "      <td>-0.460058</td>\n",
              "      <td>-0.534567</td>\n",
              "      <td>-0.630717</td>\n",
              "      <td>-0.296289</td>\n",
              "      <td>-0.167880</td>\n",
              "      <td>-0.517068</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.213746</td>\n",
              "      <td>-0.525289</td>\n",
              "      <td>-0.176915</td>\n",
              "      <td>-0.379766</td>\n",
              "      <td>-0.166227</td>\n",
              "      <td>-0.313631</td>\n",
              "      <td>-0.047868</td>\n",
              "      <td>-0.033083</td>\n",
              "      <td>5.987500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>282.000000</td>\n",
              "      <td>-0.382618</td>\n",
              "      <td>0.285843</td>\n",
              "      <td>0.905435</td>\n",
              "      <td>0.395919</td>\n",
              "      <td>-0.116612</td>\n",
              "      <td>-0.109581</td>\n",
              "      <td>0.116329</td>\n",
              "      <td>0.034755</td>\n",
              "      <td>-0.082270</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.075802</td>\n",
              "      <td>-0.076551</td>\n",
              "      <td>-0.048353</td>\n",
              "      <td>0.091886</td>\n",
              "      <td>0.143723</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>0.023199</td>\n",
              "      <td>0.021034</td>\n",
              "      <td>16.665000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>432.000000</td>\n",
              "      <td>1.110739</td>\n",
              "      <td>0.885745</td>\n",
              "      <td>1.532969</td>\n",
              "      <td>1.117559</td>\n",
              "      <td>0.452818</td>\n",
              "      <td>0.482972</td>\n",
              "      <td>0.575390</td>\n",
              "      <td>0.252395</td>\n",
              "      <td>0.412261</td>\n",
              "      <td>...</td>\n",
              "      <td>0.095149</td>\n",
              "      <td>0.307438</td>\n",
              "      <td>0.070085</td>\n",
              "      <td>0.426339</td>\n",
              "      <td>0.425798</td>\n",
              "      <td>0.260408</td>\n",
              "      <td>0.112199</td>\n",
              "      <td>0.087023</td>\n",
              "      <td>55.527500</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>581.000000</td>\n",
              "      <td>1.586093</td>\n",
              "      <td>5.267376</td>\n",
              "      <td>3.772857</td>\n",
              "      <td>4.075817</td>\n",
              "      <td>7.672544</td>\n",
              "      <td>5.122103</td>\n",
              "      <td>4.808426</td>\n",
              "      <td>2.134599</td>\n",
              "      <td>5.459274</td>\n",
              "      <td>...</td>\n",
              "      <td>5.273420</td>\n",
              "      <td>1.574750</td>\n",
              "      <td>3.150413</td>\n",
              "      <td>1.215279</td>\n",
              "      <td>1.136720</td>\n",
              "      <td>3.087444</td>\n",
              "      <td>2.490503</td>\n",
              "      <td>1.575380</td>\n",
              "      <td>3828.040000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Time          V1          V2          V3          V4          V5  \\\n",
              "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
              "mean   283.005181   -0.176963    0.217169    0.875172    0.285628   -0.005029   \n",
              "std    171.834196    1.294724    1.173401    1.031878    1.258758    1.098143   \n",
              "min      0.000000   -6.093248  -12.114213   -5.694973   -4.657545   -6.631951   \n",
              "25%    126.500000   -0.896416   -0.174684    0.308677   -0.460058   -0.534567   \n",
              "50%    282.000000   -0.382618    0.285843    0.905435    0.395919   -0.116612   \n",
              "75%    432.000000    1.110739    0.885745    1.532969    1.117559    0.452818   \n",
              "max    581.000000    1.586093    5.267376    3.772857    4.075817    7.672544   \n",
              "\n",
              "               V6          V7          V8          V9  ...         V21  \\\n",
              "count  772.000000  772.000000  772.000000  772.000000  ...  772.000000   \n",
              "mean     0.159081    0.123329   -0.057547   -0.030384  ...    0.004888   \n",
              "std      1.225682    0.852075    0.830144    0.878183  ...    0.609335   \n",
              "min     -3.498447   -4.925568   -7.494658   -2.770089  ...   -4.134608   \n",
              "25%     -0.630717   -0.296289   -0.167880   -0.517068  ...   -0.213746   \n",
              "50%     -0.109581    0.116329    0.034755   -0.082270  ...   -0.075802   \n",
              "75%      0.482972    0.575390    0.252395    0.412261  ...    0.095149   \n",
              "max      5.122103    4.808426    2.134599    5.459274  ...    5.273420   \n",
              "\n",
              "              V22         V23         V24         V25         V26         V27  \\\n",
              "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
              "mean    -0.096995   -0.040344   -0.002501    0.114337    0.022782    0.023353   \n",
              "std      0.607228    0.358724    0.621507    0.429667    0.484227    0.300934   \n",
              "min     -2.776923   -3.553381   -1.867208   -1.389079   -1.243924   -2.377933   \n",
              "25%     -0.525289   -0.176915   -0.379766   -0.166227   -0.313631   -0.047868   \n",
              "50%     -0.076551   -0.048353    0.091886    0.143723   -0.026414    0.023199   \n",
              "75%      0.307438    0.070085    0.426339    0.425798    0.260408    0.112199   \n",
              "max      1.574750    3.150413    1.215279    1.136720    3.087444    2.490503   \n",
              "\n",
              "              V28       Amount       Class  \n",
              "count  772.000000   772.000000  772.000000  \n",
              "mean    -0.017045    68.668290    0.011658  \n",
              "std      0.278332   197.838269    0.107411  \n",
              "min     -2.735623     0.000000    0.000000  \n",
              "25%     -0.033083     5.987500    0.000000  \n",
              "50%      0.021034    16.665000    0.000000  \n",
              "75%      0.087023    55.527500    0.000000  \n",
              "max      1.575380  3828.040000    1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check for missing values and basic statistics\n",
        "print(\"Missing Values:\", df.isnull().sum().sum())\n",
        "print(\"\\nDataset Statistics:\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "CLASS DISTRIBUTION ANALYSIS\n",
            "==================================================\n",
            "\n",
            "Class Counts:\n",
            "Class\n",
            "0    763\n",
            "1      9\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class Distribution (Percentage):\n",
            "Class\n",
            "0    98.834197\n",
            "1     1.165803\n",
            "Name: proportion, dtype: float64\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "⚠️ The dataset is highly IMBALANCED!\n",
            "   Ratio of Legitimate to Fraud: 84.78:1\n"
          ]
        }
      ],
      "source": [
        "# Check class distribution (Imbalance Analysis)\n",
        "print(\"=\"*50)\n",
        "print(\"CLASS DISTRIBUTION ANALYSIS\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\nClass Counts:\")\n",
        "print(df['Class'].value_counts())\n",
        "print(\"\\nClass Distribution (Percentage):\")\n",
        "print(df['Class'].value_counts(normalize=True) * 100)\n",
        "\n",
        "# Visualize class distribution\n",
        "plt.figure(figsize=(10, 5))\n",
        "colors = ['#2ecc71', '#e74c3c']\n",
        "ax = df['Class'].value_counts().plot(kind='bar', color=colors, edgecolor='black', linewidth=1.5)\n",
        "plt.title('Class Distribution in Credit Card Dataset (IMBALANCED)', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Class', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.xticks([0, 1], ['Legitimate (0)', 'Fraud (1)'], rotation=0)\n",
        "\n",
        "# Add count labels on bars\n",
        "for i, v in enumerate(df['Class'].value_counts()):\n",
        "    ax.text(i, v + 5, f'{v} ({v/len(df)*100:.2f}%)', ha='center', fontweight='bold', fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n⚠️ The dataset is highly IMBALANCED!\")\n",
        "print(f\"   Ratio of Legitimate to Fraud: {df['Class'].value_counts()[0]/df['Class'].value_counts()[1]:.2f}:1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Prepare Features and Target Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features shape: (772, 30)\n",
            "Target shape: (772,)\n",
            "\n",
            "Original class distribution: Counter({0: 763, 1: 9})\n"
          ]
        }
      ],
      "source": [
        "# Separate features and target\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"\\nOriginal class distribution: {Counter(y)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 540\n",
            "Testing set size: 232\n",
            "\n",
            "Training class distribution: Counter({0: 534, 1: 6})\n",
            "Testing class distribution: Counter({0: 229, 1: 3})\n"
          ]
        }
      ],
      "source": [
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets (70% train, 30% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Testing set size: {X_test.shape[0]}\")\n",
        "print(f\"\\nTraining class distribution: {Counter(y_train)}\")\n",
        "print(f\"Testing class distribution: {Counter(y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Define and Apply 5 Sampling Techniques\n",
        "\n",
        "| Sampling | Technique | Description |\n",
        "|----------|-----------|-------------|\n",
        "| Sampling1 | Random Under-Sampling | Reduces majority class by random removal |\n",
        "| Sampling2 | Random Over-Sampling | Increases minority class by random duplication |\n",
        "| Sampling3 | SMOTE | Creates synthetic minority samples |\n",
        "| Sampling4 | ADASYN | Adaptive synthetic sampling focusing on difficult examples |\n",
        "| Sampling5 | Tomek Links | Removes borderline majority samples |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define sampling techniques\n",
        "samplers = {\n",
        "    'Sampling1': RandomUnderSampler(random_state=42),\n",
        "    'Sampling2': RandomOverSampler(random_state=42),\n",
        "    'Sampling3': SMOTE(random_state=42),\n",
        "    'Sampling4': ADASYN(random_state=42),\n",
        "    'Sampling5': TomekLinks()\n",
        "}\n",
        "\n",
        "sampling_names = {\n",
        "    'Sampling1': 'Random Under-Sampling',\n",
        "    'Sampling2': 'Random Over-Sampling',\n",
        "    'Sampling3': 'SMOTE',\n",
        "    'Sampling4': 'ADASYN',\n",
        "    'Sampling5': 'Tomek Links'\n",
        "}\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"SAMPLING TECHNIQUES DEFINED\")\n",
        "print(\"=\"*60)\n",
        "for key, name in sampling_names.items():\n",
        "    print(f\"  {key}: {name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply sampling techniques and store the resampled datasets\n",
        "sampled_datasets = {}\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"APPLYING SAMPLING TECHNIQUES\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nOriginal Training Set: {Counter(y_train)}\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "for name, sampler in samplers.items():\n",
        "    try:\n",
        "        X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "        sampled_datasets[name] = (X_resampled, y_resampled)\n",
        "        print(f\"✓ {name} ({sampling_names[name]}): {Counter(y_resampled)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ {name}: Error - {e}\")\n",
        "        sampled_datasets[name] = (X_train, y_train)\n",
        "\n",
        "print(\"-\"*60)\n",
        "print(\"All sampling techniques applied successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the effect of sampling techniques\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "colors = ['#2ecc71', '#e74c3c']\n",
        "\n",
        "# Original distribution\n",
        "original_counts = Counter(y_train)\n",
        "axes[0].bar(['Legitimate (0)', 'Fraud (1)'], [original_counts[0], original_counts[1]], \n",
        "            color=colors, edgecolor='black', linewidth=1.5)\n",
        "axes[0].set_title('Original (Imbalanced)', fontweight='bold', fontsize=12)\n",
        "axes[0].set_ylabel('Count')\n",
        "for i, v in enumerate([original_counts[0], original_counts[1]]):\n",
        "    axes[0].text(i, v + 2, str(v), ha='center', fontweight='bold')\n",
        "\n",
        "# Sampled distributions\n",
        "for idx, (name, (X_res, y_res)) in enumerate(sampled_datasets.items(), 1):\n",
        "    counts = Counter(y_res)\n",
        "    axes[idx].bar(['Legitimate (0)', 'Fraud (1)'], [counts[0], counts[1]], \n",
        "                  color=colors, edgecolor='black', linewidth=1.5)\n",
        "    axes[idx].set_title(f'{name}\\n({sampling_names[name]})', fontweight='bold', fontsize=11)\n",
        "    axes[idx].set_ylabel('Count')\n",
        "    for i, v in enumerate([counts[0], counts[1]]):\n",
        "        axes[idx].text(i, v + 2, str(v), ha='center', fontweight='bold')\n",
        "\n",
        "plt.suptitle('Class Distribution After Different Sampling Techniques', \n",
        "             fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Define 5 Machine Learning Models\n",
        "\n",
        "| Model | Algorithm | Description |\n",
        "|-------|-----------|-------------|\n",
        "| M1 | Logistic Regression | Linear classifier for binary classification |\n",
        "| M2 | Decision Tree | Tree-based classifier using feature splits |\n",
        "| M3 | Random Forest | Ensemble of decision trees |\n",
        "| M4 | SVM | Support Vector Machine with RBF kernel |\n",
        "| M5 | KNN | K-Nearest Neighbors classifier |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define ML models\n",
        "models = {\n",
        "    'M1': ('Logistic Regression', LogisticRegression(max_iter=1000, random_state=42)),\n",
        "    'M2': ('Decision Tree', DecisionTreeClassifier(random_state=42)),\n",
        "    'M3': ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    'M4': ('SVM', SVC(kernel='rbf', random_state=42)),\n",
        "    'M5': ('KNN', KNeighborsClassifier(n_neighbors=5))\n",
        "}\n",
        "\n",
        "model_names = {key: name for key, (name, _) in models.items()}\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"MACHINE LEARNING MODELS DEFINED\")\n",
        "print(\"=\"*60)\n",
        "for key, (name, _) in models.items():\n",
        "    print(f\"  {key}: {name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Train All Models with All Sampling Techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a results dataframe to store accuracy scores\n",
        "results = pd.DataFrame(\n",
        "    index=['M1', 'M2', 'M3', 'M4', 'M5'],\n",
        "    columns=['Sampling1', 'Sampling2', 'Sampling3', 'Sampling4', 'Sampling5']\n",
        ")\n",
        "\n",
        "# Train and evaluate each model with each sampling technique\n",
        "print(\"=\"*70)\n",
        "print(\"TRAINING MODELS ON ALL SAMPLING TECHNIQUES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for model_key, (model_name, model_template) in models.items():\n",
        "    print(f\"\\n📊 {model_key} - {model_name}:\")\n",
        "    print(\"-\"*50)\n",
        "    \n",
        "    for sampling_name, (X_sampled, y_sampled) in sampled_datasets.items():\n",
        "        # Create a fresh copy of the model\n",
        "        model = clone(model_template)\n",
        "        \n",
        "        # Train the model\n",
        "        model.fit(X_sampled, y_sampled)\n",
        "        \n",
        "        # Predict on test set\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "        \n",
        "        # Store the result\n",
        "        results.loc[model_key, sampling_name] = round(accuracy, 2)\n",
        "        \n",
        "        print(f\"   {sampling_name}: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✓ TRAINING COMPLETE!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Results Table - Accuracy Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the final results table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ACCURACY RESULTS TABLE (%)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Convert to float for proper display\n",
        "results = results.astype(float)\n",
        "\n",
        "# Display raw table\n",
        "print(\"\\n\" + results.to_string())\n",
        "\n",
        "# Display with model names\n",
        "print(\"\\n\\nDetailed Results:\")\n",
        "results_with_names = results.copy()\n",
        "results_with_names.index = [\n",
        "    'M1 (Logistic Regression)',\n",
        "    'M2 (Decision Tree)',\n",
        "    'M3 (Random Forest)',\n",
        "    'M4 (SVM)',\n",
        "    'M5 (KNN)'\n",
        "]\n",
        "results_with_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a heatmap visualization of results\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Create heatmap\n",
        "sns.heatmap(\n",
        "    results.astype(float), \n",
        "    annot=True, \n",
        "    fmt='.2f', \n",
        "    cmap='RdYlGn',\n",
        "    linewidths=1,\n",
        "    linecolor='white',\n",
        "    cbar_kws={'label': 'Accuracy (%)'},\n",
        "    annot_kws={'size': 12, 'weight': 'bold'}\n",
        ")\n",
        "\n",
        "plt.title('Model Performance Across Different Sampling Techniques\\n(Accuracy %)', \n",
        "          fontsize=14, fontweight='bold', pad=20)\n",
        "plt.xlabel('Sampling Technique', fontsize=12)\n",
        "plt.ylabel('Model', fontsize=12)\n",
        "\n",
        "# Add model names as y-axis labels\n",
        "model_labels = [\n",
        "    'M1 (Logistic Regression)',\n",
        "    'M2 (Decision Tree)',\n",
        "    'M3 (Random Forest)',\n",
        "    'M4 (SVM)',\n",
        "    'M5 (KNN)'\n",
        "]\n",
        "plt.yticks(np.arange(0.5, 5.5, 1), model_labels, rotation=0, fontsize=10)\n",
        "\n",
        "# Add sampling technique names\n",
        "sampling_labels = [\n",
        "    'Sampling1\\n(Under-Sampling)',\n",
        "    'Sampling2\\n(Over-Sampling)',\n",
        "    'Sampling3\\n(SMOTE)',\n",
        "    'Sampling4\\n(ADASYN)',\n",
        "    'Sampling5\\n(Tomek Links)'\n",
        "]\n",
        "plt.xticks(np.arange(0.5, 5.5, 1), sampling_labels, fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Determine Best Sampling Technique for Each Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find the best sampling technique for each model\n",
        "print(\"=\"*70)\n",
        "print(\"BEST SAMPLING TECHNIQUE FOR EACH MODEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "best_for_model = {}\n",
        "for model_key in results.index:\n",
        "    best_sampling = results.loc[model_key].idxmax()\n",
        "    best_accuracy = results.loc[model_key].max()\n",
        "    best_for_model[model_key] = (best_sampling, best_accuracy)\n",
        "    print(f\"\\n🏆 {model_key} ({model_names[model_key]}):\")\n",
        "    print(f\"   Best Sampling: {best_sampling} ({sampling_names[best_sampling]})\")\n",
        "    print(f\"   Accuracy: {best_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find the best model for each sampling technique\n",
        "print(\"=\"*70)\n",
        "print(\"BEST MODEL FOR EACH SAMPLING TECHNIQUE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "best_for_sampling = {}\n",
        "for sampling_name in results.columns:\n",
        "    best_model = results[sampling_name].idxmax()\n",
        "    best_accuracy = results[sampling_name].max()\n",
        "    best_for_sampling[sampling_name] = (best_model, best_accuracy)\n",
        "    print(f\"\\n🏆 {sampling_name} ({sampling_names[sampling_name]}):\")\n",
        "    print(f\"   Best Model: {best_model} ({model_names[best_model]})\")\n",
        "    print(f\"   Accuracy: {best_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find overall best combination\n",
        "print(\"=\"*70)\n",
        "print(\"🎯 OVERALL BEST COMBINATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Find max value\n",
        "max_accuracy = results.max().max()\n",
        "\n",
        "# Find the position(s) of max value\n",
        "print(\"\\nHighest Accuracy Achieved:\")\n",
        "for model_key in results.index:\n",
        "    for sampling_col in results.columns:\n",
        "        if results.loc[model_key, sampling_col] == max_accuracy:\n",
        "            print(f\"\\n   ✅ Model: {model_key} ({model_names[model_key]})\")\n",
        "            print(f\"   ✅ Sampling: {sampling_col} ({sampling_names[sampling_col]})\")\n",
        "            print(f\"   ✅ Accuracy: {max_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create grouped bar chart\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "x = np.arange(len(results.index))\n",
        "width = 0.15\n",
        "multiplier = 0\n",
        "\n",
        "colors = ['#e74c3c', '#3498db', '#2ecc71', '#9b59b6', '#f39c12']\n",
        "\n",
        "for idx, sampling_col in enumerate(results.columns):\n",
        "    offset = width * multiplier\n",
        "    bars = ax.bar(x + offset, results[sampling_col].values, width, \n",
        "                  label=f'{sampling_col} ({sampling_names[sampling_col]})', \n",
        "                  color=colors[idx], edgecolor='black', linewidth=0.5)\n",
        "    multiplier += 1\n",
        "\n",
        "ax.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Model Accuracy Comparison Across Sampling Techniques', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x + width * 2)\n",
        "ax.set_xticklabels([f'{k}\\n({model_names[k]})' for k in results.index], fontsize=10)\n",
        "ax.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize=9)\n",
        "ax.set_ylim(0, 110)\n",
        "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "# Add a horizontal line at max accuracy\n",
        "ax.axhline(y=max_accuracy, color='red', linestyle='--', alpha=0.7, label=f'Max: {max_accuracy:.2f}%')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create line chart showing trends\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "markers = ['o', 's', '^', 'D', 'v']\n",
        "colors = ['#e74c3c', '#3498db', '#2ecc71', '#9b59b6', '#f39c12']\n",
        "\n",
        "for idx, model_key in enumerate(results.index):\n",
        "    ax.plot(results.columns, results.loc[model_key].values, \n",
        "            marker=markers[idx], linewidth=2.5, markersize=10,\n",
        "            label=f'{model_key} ({model_names[model_key]})',\n",
        "            color=colors[idx], markeredgecolor='black', markeredgewidth=1)\n",
        "\n",
        "ax.set_xlabel('Sampling Technique', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Model Performance Trends Across Sampling Techniques', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='best', fontsize=10)\n",
        "ax.grid(True, alpha=0.3, linestyle='--')\n",
        "ax.set_ylim(0, 105)\n",
        "\n",
        "# Rotate x-axis labels\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Summary Table and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive summary table\n",
        "print(\"=\"*90)\n",
        "print(\"COMPREHENSIVE SUMMARY TABLE\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "summary_data = []\n",
        "for model_key in results.index:\n",
        "    best_sampling = results.loc[model_key].idxmax()\n",
        "    best_accuracy = results.loc[model_key].max()\n",
        "    worst_sampling = results.loc[model_key].idxmin()\n",
        "    worst_accuracy = results.loc[model_key].min()\n",
        "    avg_accuracy = results.loc[model_key].mean()\n",
        "    \n",
        "    summary_data.append({\n",
        "        'Model': f'{model_key} ({model_names[model_key]})',\n",
        "        'Best Sampling': best_sampling,\n",
        "        'Best Acc (%)': best_accuracy,\n",
        "        'Worst Sampling': worst_sampling,\n",
        "        'Worst Acc (%)': worst_accuracy,\n",
        "        'Avg Acc (%)': round(avg_accuracy, 2)\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(\"\\n\")\n",
        "summary_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final formatted results table (matching assignment format)\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL ACCURACY RESULTS TABLE (As Required in Assignment)\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\n{:<8} {:>12} {:>12} {:>12} {:>12} {:>12}\".format(\n",
        "    '', 'Sampling1', 'Sampling2', 'Sampling3', 'Sampling4', 'Sampling5'))\n",
        "print(\"-\"*80)\n",
        "\n",
        "for model_key in results.index:\n",
        "    row = results.loc[model_key]\n",
        "    print(\"{:<8} {:>12.2f} {:>12.2f} {:>12.2f} {:>12.2f} {:>12.2f}\".format(\n",
        "        model_key, row['Sampling1'], row['Sampling2'], row['Sampling3'], \n",
        "        row['Sampling4'], row['Sampling5']))\n",
        "\n",
        "print(\"-\"*80)\n",
        "print(\"\\nLegend:\")\n",
        "print(\"  Models:\")\n",
        "print(\"    M1 = Logistic Regression\")\n",
        "print(\"    M2 = Decision Tree\")\n",
        "print(\"    M3 = Random Forest\")\n",
        "print(\"    M4 = SVM (Support Vector Machine)\")\n",
        "print(\"    M5 = KNN (K-Nearest Neighbors)\")\n",
        "print(\"\\n  Sampling Techniques:\")\n",
        "print(\"    Sampling1 = Random Under-Sampling\")\n",
        "print(\"    Sampling2 = Random Over-Sampling\")\n",
        "print(\"    Sampling3 = SMOTE\")\n",
        "print(\"    Sampling4 = ADASYN\")\n",
        "print(\"    Sampling5 = Tomek Links\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discussion and Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\"\"\n",
        "================================================================================\n",
        "                        DISCUSSION AND CONCLUSIONS\n",
        "================================================================================\n",
        "\n",
        "1. IMPACT OF SAMPLING TECHNIQUES ON MODEL PERFORMANCE:\n",
        "   ─────────────────────────────────────────────────────\n",
        "   • Different sampling techniques have varying effects on different ML models.\n",
        "   • No single sampling technique is universally best for all models.\n",
        "   • The choice of sampling technique should be based on the specific model \n",
        "     and the nature of the dataset.\n",
        "\n",
        "2. SAMPLING TECHNIQUES ANALYSIS:\n",
        "   ──────────────────────────────\n",
        "   • Sampling1 (Random Under-Sampling): \n",
        "     - Reduces majority class by random removal\n",
        "     - Fast but may lose important information\n",
        "     - Works well when majority class has redundant samples\n",
        "   \n",
        "   • Sampling2 (Random Over-Sampling): \n",
        "     - Duplicates minority class samples randomly\n",
        "     - May cause overfitting due to exact duplicates\n",
        "     - Simple and computationally efficient\n",
        "   \n",
        "   • Sampling3 (SMOTE): \n",
        "     - Creates synthetic minority samples using interpolation\n",
        "     - Reduces overfitting compared to random oversampling\n",
        "     - Widely used and effective technique\n",
        "   \n",
        "   • Sampling4 (ADASYN): \n",
        "     - Adaptive synthetic sampling\n",
        "     - Focuses on generating samples near difficult examples\n",
        "     - Good for handling noisy data boundaries\n",
        "   \n",
        "   • Sampling5 (Tomek Links): \n",
        "     - Removes borderline majority samples\n",
        "     - Cleans the decision boundary\n",
        "     - Conservative approach, keeps most original data\n",
        "\n",
        "3. KEY OBSERVATIONS:\n",
        "   ──────────────────\n",
        "   • Tree-based models (Decision Tree, Random Forest) often handle \n",
        "     imbalanced data better due to their hierarchical decision structure.\n",
        "   • Linear models (Logistic Regression) typically benefit more from \n",
        "     balanced sampling techniques.\n",
        "   • Oversampling techniques (SMOTE, ADASYN) generally provide better \n",
        "     results than under-sampling for preserving data information.\n",
        "\n",
        "4. RECOMMENDATIONS:\n",
        "   ─────────────────\n",
        "   • For credit card fraud detection, accuracy alone may not be the best \n",
        "     metric - consider precision, recall, and F1-score as well.\n",
        "   • SMOTE and ADASYN are recommended for real-world applications as \n",
        "     they create synthetic samples without losing original data.\n",
        "   • Always validate results using cross-validation for more robust \n",
        "     performance estimates.\n",
        "\"\"\")\n",
        "\n",
        "# Print the best overall result\n",
        "print(\"=\"*80)\n",
        "print(\"FINAL RECOMMENDATION:\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nBased on the accuracy results, the best combination is:\")\n",
        "for model_key in results.index:\n",
        "    for sampling_col in results.columns:\n",
        "        if results.loc[model_key, sampling_col] == max_accuracy:\n",
        "            print(f\"  → Model: {model_key} ({model_names[model_key]})\")\n",
        "            print(f\"  → Sampling: {sampling_col} ({sampling_names[sampling_col]})\")\n",
        "            print(f\"  → Accuracy: {max_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results to CSV file\n",
        "results.to_csv('sampling_results.csv')\n",
        "print(\"✓ Results saved to 'sampling_results.csv'\")\n",
        "\n",
        "# Display the final results dataframe\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL RESULTS DATAFRAME\")\n",
        "print(\"=\"*80)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assignment Completion Summary\n",
        "\n",
        "### ✅ Task 1: Dataset Downloaded\n",
        "- Credit card dataset loaded from `Creditcard_data.csv`\n",
        "\n",
        "### ✅ Task 2: Converted to Balanced Dataset\n",
        "- Applied 5 different sampling techniques to balance the imbalanced dataset\n",
        "\n",
        "### ✅ Task 3: Created Five Samples\n",
        "- Sampling1: Random Under-Sampling\n",
        "- Sampling2: Random Over-Sampling\n",
        "- Sampling3: SMOTE\n",
        "- Sampling4: ADASYN\n",
        "- Sampling5: Tomek Links\n",
        "\n",
        "### ✅ Task 4: Applied 5 Sampling Techniques on 5 ML Models\n",
        "- M1: Logistic Regression\n",
        "- M2: Decision Tree\n",
        "- M3: Random Forest\n",
        "- M4: SVM\n",
        "- M5: KNN\n",
        "\n",
        "### ✅ Task 5: Determined Best Sampling Technique for Each Model\n",
        "- Results table generated with accuracy percentages\n",
        "- Best combinations identified\n",
        "\n",
        "### 📊 Results Match Assignment Format\n",
        "The results table above shows accuracy (%) for each Model-Sampling combination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
